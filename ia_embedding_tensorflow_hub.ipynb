{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1CP1Ec8R8O3eY6vxFbz8w80STCNWnRGyO",
      "authorship_tag": "ABX9TyPLMOvUpwR/5oDYAR7Mh+n/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusds2020/ia_embedding_tensorflow_hub/blob/main/ia_embedding_tensorflow_hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do ambiente:"
      ],
      "metadata": {
        "id": "2b4G9E0gvxEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "numpy\n",
        "langchain_community\n",
        "langchain_groq\n",
        "langchain\n",
        "python-dotenv\n",
        "tensorflow\n",
        "tensorflow_hub\n",
        "pypdf\n",
        "chromadb"
      ],
      "metadata": {
        "id": "UAKWqxnpAfer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1d6466-44da-4aed-be36-e23cbebe88fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet -r requirements.txt"
      ],
      "metadata": {
        "id": "Kh4cggOovyCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "ZLoSCsGb7W3K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bloco de codigo para VSCode:\n",
        "# import os\n",
        "#from dotenv import load_dotenv\n",
        "\n",
        "# Carrega as variáveis do arquivo .env\n",
        "#load_dotenv()\n",
        "\n",
        "# Acesse as variáveis de ambiente\n",
        "#api_key = os.getenv(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "QgSAHgSG73Rf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração dos modelos e dos documentos para analise via llm"
      ],
      "metadata": {
        "id": "40JabACO7HCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acesse as variáveis de ambiente\n",
        "api_key = userdata.get('groqsecret')"
      ],
      "metadata": {
        "id": "KyLWz1OJ8FUo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o PDF\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/geopy-readthedocs-io-en-latest.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "ieSHfNqE8Iil"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o modelo de embeddings do TensorFlow Hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "metadata": {
        "id": "V2X5RF6t8JSk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define uma função de embeddings para Chroma\n",
        "class TensorFlowEmbeddingFunction:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        # Gera os embeddings para documentos\n",
        "        embeddings = self.model(texts)\n",
        "        return embeddings.numpy().tolist()  # Converte para uma lista de embeddings\n",
        "\n",
        "    def embed_query(self, query):\n",
        "        # Gera o embedding para a consulta\n",
        "        query_embedding = self.model([query])\n",
        "        return query_embedding.numpy().tolist()[0]  # Retorna como uma lista"
      ],
      "metadata": {
        "id": "jLGRrRWR8PS1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Armazenamento de vetores usando Chroma db"
      ],
      "metadata": {
        "id": "Cc6fmU507tFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria uma instância da função de embeddings\n",
        "embedding_function = TensorFlowEmbeddingFunction(embed)\n",
        "\n",
        "# Divide o texto em chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=250)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "\n",
        "# Cria o armazenamento de vetores usando Chroma\n",
        "vectorstore = Chroma.from_documents(texts, embedding_function)"
      ],
      "metadata": {
        "id": "DylDTupE8R_k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consulta de documentos"
      ],
      "metadata": {
        "id": "iKVOuIXE71nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializa o modelo LLM\n",
        "llm = ChatGroq(temperature=0.3, groq_api_key=api_key, model_name=\"mixtral-8x7b-32768\")"
      ],
      "metadata": {
        "id": "L_Poj9C88T80"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)\n",
        "query = \"É possivel utilizar o pandas dataframe? e responda em portugues do Brasil\"\n",
        "result = pdf_qa.invoke({\"question\": query, \"chat_history\": []})"
      ],
      "metadata": {
        "id": "hgCLt4sbV6tI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3trSf1VFGKra",
        "outputId": "15371b23-3c5e-4d64-d5a8-04b4ccf20c34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['question', 'chat_history', 'answer', 'source_documents'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(result['answer'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "kNNVLm7pFdFC",
        "outputId": "17e8fc7e-2b0f-41b4-e9f1-94b283196a9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Sim, é possível utilizar o DataFrame do pandas em conjunto com a biblioteca Geopy para geocodificar endereços e calcular distâncias entre pontos. No exemplo fornecido, é demonstrado como usar o DataFrame para armazenar os nomes das cidades e, em seguida, aplicar a função de geocodificação a cada nome de cidade para obter as localizações geográficas correspondentes. Em seguida, é calculado o ponto (latitude, longitude, altitude) para cada localização. Além disso, é possível customizar a função de geocodificação com opções adicionais, como o idioma ou os códigos de país. Por fim, é possível utilizar a classe RateLimiter para controlar a taxa de solicitações à API de geocodificação e evitar excessos de uso.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(result['source_documents'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "jmM6s1-ZGQH0",
        "outputId": "cf756918-ce95-4f73-e38c-e9603eb86c8d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 14, 'source': '/content/drive/MyDrive/geopy-readthedocs-io-en-latest.pdf'}, page_content='GeoPy Documentation, Release 2.4.1\\nimport pandas as pd\\ndf = pd.DataFrame({ \\'name \\': [\\'paris \\',\\'berlin \\',\\'london \\']})\\nfrom geopy.geocoders import Nominatim\\ngeolocator = Nominatim(user_agent=\"specify_your_app_name_here\")\\nfrom geopy.extra.rate_limiter import RateLimiter\\ngeocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\\ndf[\\'location \\'] = df[ \\'name \\'].apply(geocode)\\ndf[\\'point \\'] = df[ \\'location \\'].apply( lambdaloc: tuple(loc.point) ifloc else None )\\nThis would produce the following DataFrame:\\n>>>df\\nname location \\\\\\n0 paris (Paris, Île-de-France, France métropolitaine, ...\\n1 berlin (Berlin, 10117, Deutschland, (52.5170365, 13.3...\\n2 london (London, Greater London, England, SW1A 2DU, UK...\\npoint\\n0 (48.8566101, 2.3514992, 0.0)\\n1 (52.5170365, 13.3888599, 0.0)\\n2 (51.5073219, -0.1276474, 0.0)\\nTo pass extra options to the geocodecall:\\nfrom functools import partial\\ndf[\\'location \\'] = df[ \\'name \\'].apply(partial(geocode, language= \\'de\\'))\\nTo see a progress bar:\\nfrom tqdm import tqdm\\ntqdm.pandas()\\ndf[\\'location \\'] = df[ \\'name \\'].progress_apply(geocode)\\nBeforeusingratelimitingclasses,pleaseconsultwiththeGeocodingserviceToS,whichmightexplicitlyconsiderbulk\\nrequests (even throttled) a violation.\\nclassgeopy.extra.rate_limiter. RateLimiter (func,*,min_delay_seconds=0.0 ,max_retries=2 ,\\nerror_wait_seconds=5.0 ,swallow_exceptions=True ,\\nreturn_value_on_exception=None )\\nThis is a Rate Limiter implementation for synchronous functions (like geocoders with the default geopy.\\nadapters.BaseSyncAdapter ).\\nExamples:\\nfrom geopy.extra.rate_limiter import RateLimiter\\nfrom geopy.geocoders import Nominatim\\ngeolocator = Nominatim(user_agent=\"specify_your_app_name_here\")\\nsearch = [\"moscow\", \"paris\", \"berlin\", \"tokyo\", \"beijing\"]\\ngeocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\\n(continues on next page)\\n2.6. Usage with Pandas 11'),\n",
              " Document(metadata={'page': 30, 'source': '/content/drive/MyDrive/geopy-readthedocs-io-en-latest.pdf'}, page_content='Return a location point by address.\\nParameters\\n•query(str or dict ) – The address or query you wish to geocode.\\nFor a structured query, provide a dictionary whose keys are one of: country,state,city,\\nzipcode,street,address,houseNumber orsubNumber .\\n•country_codes (str or list )–Providesthegeocoderwithalistofcountrycodesthat\\nthe query may reside in. This value will limit the geocoder to the supplied countries. The\\ncountrycodeisa2charactercodeasdefinedbytheISO-3166-1alpha-2standard(e.g. FR).\\nMultiple countries can be specified with a Python list.\\n2.18. Geolake 27'),\n",
              " Document(metadata={'page': 67, 'source': '/content/drive/MyDrive/geopy-readthedocs-io-en-latest.pdf'}, page_content='GeoPy Documentation, Release 2.4.1\\nYou can change the ellipsoid model used by the geodesic formulas like so:\\n>>>ne, cl = newport_ri, cleveland_oh\\n>>>print(distance.geodesic(ne, cl, ellipsoid= \\'GRS-80 \\').miles)\\nTheabovemodelnamewillautomaticallyberetrievedfromthe distance.ELLIPSOIDS dictionary. Alternatively,you\\ncan specify the model values directly:\\n>>>distance.geodesic(ne, cl, ellipsoid=(6377., 6356., 1 / 297.)).miles\\nDistances support simple arithmetic, making it easy to do things like calculate the length of a path:\\n>>> from geopy import Nominatim\\n>>>d = distance.distance\\n>>>g = Nominatim(user_agent=\"specify_your_app_name_here\")\\n>>>_, wa = g.geocode( \\'Washington, DC \\')\\n>>>_, pa = g.geocode( \\'Palo Alto, CA \\')\\n>>>print((d(ne, cl) + d(cl, wa) + d(wa, pa)).miles)\\n3277.30439191\\nCurrentlyallalgorithmsassumethataltitudesofthepointsareeitherzero(asintheexamplesabove)orequal,andare\\nrelatively small. Thus altitudes never affect the resulting distances:\\n>>> from geopy import distance\\n>>>newport_ri = (41.49008, -71.312796)\\n>>>cleveland_oh = (41.499498, -81.695391)\\n>>>print(distance.distance(newport_ri, cleveland_oh).km)\\n866.4554329098687\\n>>>newport_ri = (41.49008, -71.312796, 100)\\n>>>cleveland_oh = (41.499498, -81.695391, 100)\\n>>>print(distance.distance(newport_ri, cleveland_oh).km)\\n866.4554329098687\\nIf you need to calculate distances with elevation, then for short distances the Euclidean distance formula might give a\\nsuitable approximation:\\n>>> import math\\n>>> from geopy import distance\\n>>>p1 = (43.668613, 40.258916, 0.976)\\n>>>p2 = (43.658852, 40.250839, 1.475)\\n>>>flat_distance = distance.distance(p1[:2], p2[:2]).km\\n>>>print(flat_distance)\\n1.265133525952866\\n>>>euclidian_distance = math.sqrt(flat_distance**2 + (p2[2] - p1[2])**2)\\n>>>print(euclidian_distance)\\n1.359986705262199\\nAn attempt to calculate distances between points with different altitudes would result in a ValueError exception.\\ngeopy.distance. lonlat(x,y,z=0)'),\n",
              " Document(metadata={'page': 70, 'source': '/content/drive/MyDrive/geopy-readthedocs-io-en-latest.pdf'}, page_content='GeoPy Documentation, Release 2.4.1\\n(continued from previous page)\\nPoint(33.995238229104764, 149.08238904409637, 0.0)\\nReturn type geopy.point.Point\\nclassgeopy.distance. geodesic (*args,**kwargs)\\nBases: geopy.distance.Distance\\nCalculate the geodesic distance between points.\\nSet which ellipsoidal model of the earth to use by specifying an ellipsoid keyword argument. The default is\\n‘WGS-84’, which is the most globally accurate model. If ellipsoid is a string, it is looked up in the ELLIP-\\nSOIDSdictionarytoobtainthemajorandminorsemiaxesandtheflattening. Otherwise,itshouldbeatuplewith\\nthose values. See the comments above the ELLIPSOIDS dictionary for more information.\\nExample:\\n>>> from geopy.distance import geodesic\\n>>>newport_ri = (41.49008, -71.312796)\\n>>>cleveland_oh = (41.499498, -81.695391)\\n>>>print(geodesic(newport_ri, cleveland_oh).miles)\\n538.390445368\\nclassgeopy.distance. great_circle (*args,**kwargs)\\nBases: geopy.distance.Distance\\nUse spherical geometry to calculate the surface distance between points.\\nSet which radius of the earth to use by specifying a radiuskeyword argument. It must be in kilometers. The\\ndefault is to use the module constant EARTH_RADIUS , which uses the average great-circle radius.\\nExample:\\n>>> from geopy.distance import great_circle\\n>>>newport_ri = (41.49008, -71.312796)\\n>>>cleveland_oh = (41.499498, -81.695391)\\n>>>print(great_circle(newport_ri, cleveland_oh).miles)\\n536.997990696\\n67')]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AutSps-lGZ34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}